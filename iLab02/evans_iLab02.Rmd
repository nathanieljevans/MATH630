---
title: "evans_iLab02"
author: "Nathaniel Evans"
date: "October 20, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse) # all the good stuff
library(readxl) # for reading in xlsx files
library(janitor) # for clean_names
library(knitr) # for kable
library(moderndive) # for getting tables
library(corrr) # for correlation matrix
library(skimr) # for skim
library(GGally) # for ggpairs
library(broom) # for pulling out model results
library(rdryad) # to access the API
library(purrr) # for 1 function: pluck!
```

```{r data aquisition}
path_to_xlsx <- dryad_fetch(dryad_files(doi = '10.5061/dryad.7763s/1')) %>% 
  pluck(1)
vitd <- read_xlsx(path_to_xlsx, sheet = 1)
vitd <- vitd %>% 
  clean_names()
#glimpse(vitd)

codebook <- read_xlsx(path_to_xlsx, sheet = 2)

lm_vars <- c("sex", "_zhfa", "ageyears", "_25D")
codebook %>% 
  filter(Variable %in% lm_vars) %>% 
  knitr::kable()

lm_data <- vitd %>% select(c("sex", "zhfa", "ageyears", "x25d"))

```

# EDA 


```{r EDA}
glimpse(lm_data)
ggpairs(data=lm_data)

```

## GGpair analysis  
There appears to be a weak inverse correllation between x25d, zhfa and age. There is also a significant difference in x25d values between sex, which indicates an interaction model may be valuable. x25d exhibits some kurtosis and age seems to have two modes, which deserves some looking into (especially if the modes correllate to male/female - might explain diff in sex x25D and sex data). 

```{r age modality question} 
lm_data %>% group_by(sex) %>% ggplot(aes(x = ageyears, color=sex)) + geom_density()

lm_data %>% ggpairs(aes(color=sex))
```

The bimodality doesn't seem to be attributed to sex distribution, I think this is important to explore more but I'm not sure how to approach it efficiently. 

```{r}
lm_data %>% skimr::skim()
lm_data %>% summary()

```
<br />

####How many variables/columns? <br />
We are considering only 4 variables: ageyears, x25d, sex, zhfa

####How many rows/observations? <br />
There are 537 observations. 

####Which variables are numbers? <br />
age <int> 
x25d <float>
zhfa <float> 

####Which are categorical variables (numeric or character variables with variables that have a fixed and known set of possible values; aka factor variables)? <br />
sex ["M"/"F"]

####Complete this sentence: "There is one row/observation per." <br />
school child in thailand 

####What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable (like sex)? <br />
From initial EDA, the scatterplots do not show an obvious linear correllation however the cor() function shows a slight negative correlation between the variables. sex plays a significant role in mediating the ageyears variable correlation; females show a high correllation between age and x25d. 


```{r regression model}
#lm_dataz <- lm_data %>% transmute(sex = sex, age = scale(lm_data$ageyears,center=TRUE, scale=TRUE), hgt_age= scale(lm_data$zhfa,center=TRUE, scale=TRUE), vitD = scale(lm_data$x25d, center=TRUE, scale=TRUE)) 

#glimpse(lm_dataz)

vitD_mod <- lm(data=lm_data, formula= 'x25d ~ ageyears*sex + zhfa')

vitD_mod

get_regression_summaries(model=vitD_mod)

model_pts <- get_regression_points(model=vitD_mod)



```

## Regression Model <br /> 
My regression model is described (names altered) as: 
$$ VITD = -3.1*AGE - 16.8*SEX_m - 1.73*zHFA + 3.0*AGE*SEX_m + 96.9$$


This can be described in a variety of ways, and since we are using a amalygam of units (z-score, years, boolean) it should be carefully considered to understand how it's describing the data. In this model, for each year of age, the vitD metric (x25D) decreases by 3.1 BUT the age:sex interaction shows that this is only applicable for females. Age only negligibly affects the vitD metric in males. The height for age (zhfa) zscore shows that for every increase in z score, the vitD metric decreases by 1.73. It is important to note that since zhfa has been centered, some of the data is negative, and therefore some of the zhfa terms will be net positive. Mathamatically this makes sense, but for units (like a ratio) that can't intuitively be understood as a negative number, its worth recognizing. Lastly, the data shows that males have a lower average vitD metric: If you are male then you will have -16.8 vitD that a female doppleganger would be predicted to have. The intercept is perhaps the most difficult component of the model to grasp intuitively, but I think it's fairly easily described when you recognize the bounds of this model. The bounds of the data are: 


VAR | MIN | MAX
----|-----|----
AGE | 6.2 |14.0
zhfa|-3.4 |1.8
x25D| 36  |127

With these bounds in mind, the intercept is the offset that best fits the data while the correllation coefficients determine how the data behaves within these bounds. So, as an example, for a child who is 6.2 years old, has zhfa of -3.4, the intercept compensates to bring the x25D value to within the fitted range. It should NOT be interpreted that for a baby of 0, or a child with ridiculous height for age value (like zero or negative ratio before zscore conversion) that this model predicts a x25D value, this model is ONLY valuable inside the bounds of our data. 

<span style="color:deeppink"> Responding to the original authors analysis commentss, we see similar values from our data: mean ageyears = 9.9 and zhfa = 0 -> 
VitD_females = -3.1*9.9 + 96.9 = 66.2 
VitD_males = -3.1*9.9 -16.8 + 96.9 + 3\*9.9 = 79.1 
(79.1-66.2)/66.2 => 19.5 %

Males have a 19.5% higher VitD value at the mean age of 9.9 according to this data. 

For each increasing year... 
-3.1 / 66.2 (from above) => 4.6 % decrease
... female VitD is predicted to decrease by 4.6% 
</span> 

# RESIDUAL ANALYSIS 


```{r}
#model_pts
model_pts %>% ggplot(aes(residual)) + geom_histogram(bins=20) + facet_wrap(facets=vars(sex))
model_pts %>% ggplot(aes(x=sex, y=residual, color=sex)) + geom_violin() + geom_point() 
model_pts %>% ggplot(aes(x=ageyears, y=residual, color=sex)) + geom_col() + geom_smooth()
model_pts %>% ggplot(aes(x=zhfa, y=residual)) + geom_col() + geom_smooth()
#model_pts %>% select(sex) %>% filter(sex=='M') %>% count()

```

## Residual analysis discussion 

The residual analysis shows a decently well fit model. The residual histogram faceted by sex shows normal distribution with perhaps slightly high kurtosis (how can we know for sure? - can we overlay a normal distribution curve on this?). The violin plots show expected distributions with slightly enhanced range of residuals in Males. The means and standard deviation in these two populations were near identical. The zhfa vs residual plot shows no systemic trends. The age vs residual plot, colored/grouped by sex is perhaps the most interesting plot, as it does show a slight trend indicative of a x^4 or x^5 (depending on bounds) polynomial. This trend is present in both males and females. This implies that the model does not effectively represent the age component. 

# Outlier Analysis
Examine points with high leverage and discrepancy (use the externally studentized residuals as the index for discrepancy). Remember that these statistics are not in the output of the moderndive::get_regression_points() function- you'll want to use  broom::augment() and rstudent instead.

```{r outliers}
diag <- broom::augment(vitD_mod, data = lm_data)
diag %>% select(sex,zhfa,ageyears,x25d,.hat) %>% arrange(desc(.hat)) %>% head()
glimpse(diag)

k <- 3 # age, zhfa, sex, sex*age? # <------------------- LEVERAGE
mean_hat <- (k + 1)/nrow(lm_data)
mean_hat <- mean(diag$.hat)
# "large" samples
diag %>% 
  select(sex,zhfa,ageyears,x25d,.hat) %>%
  filter(.hat > (2*mean_hat))

diag %>% ggplot(aes(x=ageyears,y=.hat, color=zhfa)) + geom_point() + facet_wrap(facets=vars(sex)) + geom_abline(slope=0, intercept=mean_hat*2) + ggtitle('leverage')
# plot .hat vs ... what? 

diag <- diag %>% mutate(high_lev = ifelse(.hat > 2*mean_hat, 'high','low'))


# discrepancy
diag <- diag %>% 
  mutate(.ext.resid = rstudent(vitD_mod)) # add 

# expect 5% are >2 --- remember >2 is considered an OUTLIER
diag %>% 
  select(sex,zhfa,ageyears,x25d, .std.resid, .ext.resid) %>% 
  arrange(desc(.ext.resid)) %>% 
  slice(1:5)

diag <- diag %>% mutate(dsicrp_high = ifelse(.ext.resid>2,'high','low'))

diag %>% ggplot(aes(x=ageyears, y=.ext.resid, color=as.factor(dsicrp_high))) + geom_point() + facet_wrap(vars(sex)) + ggtitle('discrepancy vs age')

diag %>% ggplot(aes(x=zhfa, y=.ext.resid, color=as.factor(dsicrp_high))) + geom_point() + ggtitle('discrepancy vs zhfa')

diag %>%  group_by(dsicrp_high) %>% count(sex) # 2.9% are high 

diag %>% filter(dsicrp_high=='high' & high_lev=='high')

diag %>% ggplot(aes(x=.hat, y=.ext.resid, color=sex, size=.cooksd)) + geom_point() + geom_hline(yintercept=2) + geom_vline(xintercept=2*mean_hat) + ggtitle("high influence")



```

##How many observations would you expect to have high discrepancy in this sample?</br>
Expect 5% to be greater than 2. We see 2.9% being above 2. 

##You may want to account for how many females versus males you would expect</br>
I would expect, approximately, the same number of females and males be over 2. From this data, we see double the number of males (10) than females (5) that are above a discrepancy of 2. The population is small enough (15) that I don't think this is conclusively biased but it is indicative that males are less well predicted than females. 

##Do you see any observations that have both high leverage and discrepancy?</br>
No, there are no observations that have a leverage > 2*mean_hat and discrepancy >2. 

##Do any points that are either high leverage or high discrepancy also have high influence on the regression estimates, as measured by Cook's distance?</br>
There are a few observations with high discrepancy OR high leverage and high influence, as seen from the "high influence" plot. One in particular that is far right with a high .hat value with significant influence (cooksd)

##Would you exclude any observations from your model? Justify your answer either way.</br>
No, while there are some values that have high leverage, I would not exclude them because I have no experimental justification so I can't say that they are invalid data points. 

##In general, would you say the overall model fit is better for females or males? Why or why not?</br>
There are more outliers in males than there are females so I would, hesitantly, say that it's a better model for females. 

# SUMS OF SQUARES 

```{r}
vitd_ss <- diag %>% 
  summarise(total_ss = sum((x25d - mean(x25d))^2),
            resid_ss = sum((x25d - .fitted)^2), 
            model_ss = sum((.fitted - mean(x25d))^2),
            resid_model_ss = resid_ss + model_ss,
            var_y = total_ss / (529 + 1),
            r_sqr = model_ss / total_ss)
vitd_ss

#diag %>% count()

var(diag$x25d)

broom::glance(vitD_mod)
```

## sum of squares narrative</br> 
From my data, total_ss = (resid_ss + model_ss)

variance (calculated from total_ss) = variance calculated from x25d = ~236

R2 (from ss metrics) = R2 from model = .236

# Null Model 

```{r}
vitd_complete <- vitd %>% 
  drop_na(x25d, sex, ageyears, zhfa)
int_mod <- lm(x25d ~ 1, data = vitd_complete)
get_regression_table(int_mod)

anova(int_mod, vitD_mod)

```

##What is the RSS for line 1 (corresponding to the intercept-only model, Model 1) equal to that you calculated above?</br>
$$RSS_n = 125063$$

##What is the RSS for line 2 (corresponding to Model 2) equal to that you calculated above?</br>
$$RSS_m = 95511$$

##What is the Sum of Sq equal to that you calculated above?</br>
$$model_ss_m = 29952$$
This matches what was calculated by the ANOVA function. 

##In < 3 sentences, explain what it means to use lm(y ~ x + z) versus lm(y ~ 1), and what happens "under the hood" here that you now see in the anova output.</br>

The ANOVA function is comparing the two given models, one being your null intercept-only model lm(y ~ 1)  and the other being a variable dependant model. The resultant value is a ratio of the Residual Sum of Squares of your model and the null model. So functionally, a high value indicates that your model decreases the residual sum of squares much better than a intercept only model. 

# Plot Comparison 

##What appears to be the minimum value of serum 25D levels?</br>
50 nmol/L

##What appears to be the max?</br>
82 nmol/L

##Do those match your EDA?</br>
EDA shows min 36, max of 127. So the plot min/max are within the bounds of our data. 

##Recreate this figure in ggplot2 using the observed data (ignore height-for-age z-scores at this point).</br>
```{r}
lm_data %>% ggplot(aes(x=ageyears, y=x25d, color =sex)) + geom_point()
```

##Make the same plot where the y-axis should now be mapped to the fitted value for the outcome variable (using the full model with height-for-age z-scores in it). Discuss the differences you see between this plot and the previous. Were you able to recreate the published figure? It is helpful in understanding the researchers' findings? Was it misleading at all?</br>

The figure follows the same trend but the range is a little bit larger, I suspect that the published plot removed some of the data in the outlier step. I would need to understand their process and question why or how they justify the dropping outliers. 

```{r}
diag %>% ggplot(aes(x=ageyears, y=.fitted, color=sex)) + geom_point()
```





  